# Required connection configs for Kafka producer, consumer, and admin
bootstrap.servers=pkc-6ojv2.us-west4.gcp.confluent.cloud:9092
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='{{ CLUSTER_API_KEY }}' password='{{ CLUSTER_API_SECRET }}';
sasl.mechanism=PLAIN
# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
acks=all

# Required connection configs for Confluent Cloud Schema Registry
schema.registry.url=https://psrc-3w372.australia-southeast1.gcp.confluent.cloud
basic.auth.credentials.source=USER_INFO
basic.auth.user.info={{ SR_API_KEY }}:{{ SR_API_SECRET }}

# kafka consumer group id
group.id = de-zoomcamp-nytaxi-ride-group.0
# start reading from the latest offset
auto.offset.reset=latest

# name of the topics to source/producer records to
dezoomcamp.kafka.topic.ride-counts=ride_count_by_pickup_location
dezoomcamp.kafka.topic.rides=de-zoomcamp-nytaxi-rides
dezoomcamp.kafka.topic.zones=de-zoomcamp-nytaxi-zone
dezoomcamp.kafka.topic.locations=de-zoomcamp-nytaxi-locations
dezoomcamp.kafka.topic.rides-zones=de-zoomcamp-nytaxi-rides-zones
dezoomcamp.kafka.topic.rides-avro=de-zoomcamp-nytaxi-rides-avro

# serializers
key.serializer=org.apache.kafka.common.serialization.StringSerializer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# tell KafkaJsonDeserializer which class to deserialise to
json.value.type=kafka_follow_along.Ride

# Kafka stream Properties
# stream application id
application.id=de-zoomcamp-nytaxi-rides-stream-app
# disable cachestreamer
cache.max.bytes.buffering=0 
